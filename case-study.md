# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникли 2 проблемы.
1) Необходимо было импортировать в базу файл с данными, чуть больше 32 мегабайт (100К записей).
   Рейк таск успешно работал на файлах размером пару мегабайт, но c большими файлами он работала слишком долго.
   Я решил исправить эту проблему, оптимизировав этот скрипт.

2) Страницы расписаний тоже формируются не эффективно и при росте количества записей начинают сильно тормозить.
   Я решил исправить эту проблему, оптимизировав sql-запросы.
   
## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
время выполнения программы/запроса в секундах

Бюджет метрики для импорта large.json - 60 секунд.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась без теста. Поэтому необходимо было написать тест, проверяющий корректность работы программы.
Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`,
который позволил мне получать обратную связь по эффективности сделанных изменений за ~15 секунд

Вот как я построил `feedback_loop`:
- написал тесты для проверки корректности работы рейк таски/контроллера
- измерил метрику: для рейк таски с example.json (10К записей) - 200 мс
- написал performance тесты для защиты от деградации производительности
- далее использовал эти же входные данные для дальнейшего профилирования и сравнения метрик

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался:
- rack-mini-profiler
- rails panel
- bullet
- explain запросов

Вот какие проблемы удалось найти и решить:

Ваша находка №1
- Стандартный лог в консоли показал, что выполняется очень много sql запросов при импорте
- Переписал рейк таск с использованием библиотеки activerecord-import, каждая таблица заполняется одним запросом,
  в том числе и join-таблица buses_services.
- Метрика уменьшилась с 200 до 25 мс для small.json
- Количество sql запросов в логе сильно уменьшилось. Прогон large.txt занимает 47 секунд - уложились в бюджет.